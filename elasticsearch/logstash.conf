input {
   kafka {
      bootstrap_servers => "139.196.139.165:9092"
      consumer_threads => 2
      decorate_events  => true
      topics => ["sys_log", "zabbix_alert", "website", "jump", "audit", "heartbeat", "metric", "jumplog", "ariesx", "jsys"]
  }
}

filter {
   # filebeat auditbeat，过来的都是json格式，直接通过json进行解析

   json {
      source => "message"
      skip_on_invalid_json => false
      tag_on_failure => ["failurejson"]
   }

   # [fileset][name] 是syslog 模块的索引判断, 各个途径上报数据的结构不一样，根据实际情况修改
   # [fields][index_name] 是在filebeat, auditbeat的配置文件中增加了名为 index_name 的field
   # 个人习惯是在agent端就按照规则定义好索引，logstash直接读取就好了

   if [fileset][name] {
      mutate {
         add_field => { "index_name" => "%{[fileset][name]}" }
      }
   } else if [fields][index_name] {
      mutate {
         add_field => { "index_name" => "%{[fields][index_name]}" }
      }
   } else {
      mutate {
         add_field => { "index_name" => "default_index_name" }
      }
   }

   if [fields][index_name] == "zabbix" {
      grok {
         match => { "message" => "(?<event_time>(\d{4})-(\d{2})-(\d{2}) (\d){2}:(\d){2}:(\d){2})"}
      }
      date {
         match => [ "event_time", "yyyy-MM-dd HH:mm:ss"]
         target => "@timestamp"
      }
   }


   if [fields][index_name] == "website" {
      mutate {
         add_field => {"nginx_log" => "%{[message]}" }
         add_field => {"log_file" => "%{[source]}" }
      }
      grok {
         match => {
           "nginx_log" => '%{IPORHOST:clientip} (?:-|(%{WORD}.%{WORD})) %{USER:ident} \[%{HTTPDATE:timestamp}\] "(?:%{WORD:method} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})" %{NUMBER:response} (?:%{NUMBER:bytes}|-) %{QS:referrer} %{QS:agent}'
         }
      }

      # geoip6.x以后不需要再通过网上那些方法来增加字段了，会自动生成 geoip.location字段，字段的类型为 geoip_point
      geoip {
         source => "clientip"
         target => "geoip"
         database => "/tmp/geo/GeoLite2-City.mmdb"
      }
   }

   if [fields][index_name] == "jumpserver" {
       mutate {
           add_field => {"login_log" => "%{[message]}" }
       }
       grok {
          match => {
            "login_log" => "\[(?<event_time>(\d{4})-(\d{2})-(\d{2}) (\d{2}):(\d{2}):(\d{2}))\] %{WORD:user} %{IP:ip} (?<ps>pts/(\d+))"
          }
       }
       date {
          match => [ "event_time", "yyyy-MM-dd HH:mm:ss"]
          target => "@timestamp"
       }
   }

   if [fields][index_name] == "jumplog" {
      mutate {
         gsub => ["message", "\x1B\[([0-9]{1,2}(;[0-9]{1,10})?)?[m|K|h]", ""]
         gsub => ["message", "s,\x1B\[[0-9;]*[a-zA-Z],,g", ""]
         gsub => ["message", "\][0-9]\;", ""]
         gsub => ["message", "\[\?[0-9]{1,10}\h", ""]
         gsub => ["message", "\[[a-zA-Z]\[[0-9]{1,10}[a-z][A-Z]", ""]
         gsub => ["message", "\[[0-9]{1,10}\;[0-9]{1,10}\;[0-9]{1,10}[a-zA-Z]", ""]
      }
      grok {
         match => {
            "message" => "%{WORD:user}\@jumpserver\:(?<drop>.*)\[(?<event_time>(\d{4})-(\d{2})-(\d{2}) (\d{2}):(\d{2}):(\d{2}))\] \# %{GREEDYDATA:op}"
         }
      }
      mutate {
         remove_field => [ "drop" ]
      }
      date {
         match => [ "event_time", "yyyy-MM-dd HH:mm:ss"]
         target => "@timestamp"
      }
   }

   # 迷雾大陆
   if [fields][index_name] == "ariesx" {
      json {
         source => "message"
         skip_on_invalid_json => false
         tag_on_failure => ["ariesx_failurejson"]
      }
      date {
         match => ["ts", "UNIX", "UNIX_MS"]
         target => "@timestamp"
      }
   }

   # 九死一生 jsys
   if [fields][index_name] == "jsys" {
     json {
         source => "message"
         skip_on_invalid_json => false
         tag_on_failure => ["jsys_failurejson"]
     }
     date {
         match => ["TimeStamp", "UNIX"]
         target => "@timestamp"
     }
   }

   # 对hearbeat的icmp处理
   if [monitor][type] == "icmp" {
      mutate {
         add_field => {"icmp_rtt_us" => "%{[icmp][rtt][us]}" }
         add_field => {"icmp_ip" => "%{[monitor][ip]}" }
         add_field => {"icmp_id" => "%{[monitor][id]}" }
         add_field => {"icmp_duration" => "%{[monitor][duration][us]}" }
      }
      geoip {
         source => "icmp_ip"
         target => "geoip"
         database => "/tmp/geo/GeoLite2-City.mmdb"
     }
   }
}

output {
   elasticsearch {
     hosts => ["elasticsearch-service:9200"]
     index => "%{index_name}-%{+YYYY.MM.dd}"
     sniffing => true
     manage_template => false
   }
}